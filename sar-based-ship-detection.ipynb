{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10385900,"sourceType":"datasetVersion","datasetId":6434068},{"sourceId":10406546,"sourceType":"datasetVersion","datasetId":6448805},{"sourceId":10406587,"sourceType":"datasetVersion","datasetId":6448839},{"sourceId":10406819,"sourceType":"datasetVersion","datasetId":6448999},{"sourceId":10414816,"sourceType":"datasetVersion","datasetId":6454803}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"execution_failed":"2025-01-11T11:28:13.355Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install torch torchvision","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\nimport random\nfrom pycocotools.coco import COCO\nfrom pycocotools.cocoeval import COCOeval\nimport numpy as np\nimport skimage.io as io\nimport pylab\nimport pandas as pd\nimport json\nimport matplotlib.pyplot as plt\nimport glob","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Clone github repo.\n!git clone https://github.com/ultralytics/yolov5.git\n\n# Change dir to yolov5\n%cd yolov5/\n\n# Install requirements\n!pip install -r requirements.txt\n\nimport torch\nfrom yolov5 import utils\ndisplay = utils.notebook_init()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!wget https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5m.pt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the dataset.yaml file keys.\nimport yaml\nparsed_yaml_file = dict()\nparsed_yaml_file['path'] = ''\nparsed_yaml_file['train'] = '/kaggle/input/ship-detection-sar/HRSID_YOLO/train'\nparsed_yaml_file['val'] = '/kaggle/input/ship-detection-sar/HRSID_YOLO/val'\nparsed_yaml_file['test'] = '/kaggle/input/ship-detection-sar/HRSID_YOLO/test'\nparsed_yaml_file['nc'] = 1\nparsed_yaml_file['names'] = ['Ship']\nparsed_yaml_file","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Overwrite the original .yaml file.\npath_4_saving = '/kaggle/working/dataset.yaml'\nwith open(path_4_saving, 'w') as outfile:\n    yaml.dump(parsed_yaml_file, outfile, default_flow_style=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check that the .yaml file saved correctly.\na_yaml_file = open(path_4_saving)\nparsed_yaml_file = yaml.load(a_yaml_file, Loader=yaml.FullLoader)\nparsed_yaml_file","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install wandb","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import wandb\npersonal_wandb_api_key = '182fb77b09d214e4546d4ff2422c05f1b8398b6f'\nwandb.login(key=personal_wandb_api_key)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!wandb login --relogin 182fb77b09d214e4546d4ff2422c05f1b8398b6f","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !python train.py --img 1344 --batch 16 --epochs 20 --data $path_4_saving --weights /content/yolov5/yolov5m.pt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install torch","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Launch after you have started training\n# logs save in the folder \"runs\"\n%load_ext tensorboard\n%tensorboard --logdir runs","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install google.colab","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from IPython.display import display\n# from google.colab import files\n\n# uploaded = files.upload()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Download model's weights.\n!zip -r /content/exp2.zip './runs/train/exp'\n# from google.colab import files\n# files.download('/content/exp.zip')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python val.py --weights /kaggle/input/temporary2/best2.pt --data /kaggle/working/dataset.yaml --img 1344 --iou 0.5 --task test --save-json","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_path = '/kaggle/input/ship-detection-sar/HRSID_YOLO/test/images'\nweight_path = '/kaggle/input/temporary3/last.pt'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Inference on all test images.\n!python detect.py --source $test_path --weights $weight_path --img 1344 --save-txt --save-conf --line-thickness 1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Zip the output results\nfolder_name = 'inference_on_imgs.zip'\n!zip -r $folder_name /kaggle/working/yolov5/yolov5/runs/detect/exp\n\n# Download the results\nfrom google.colab import files\nfiles.download(folder_name)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Zip the output results\nimport shutil\n\nfolder_name = 'inference_on_imgs.zip'\noutput_folder = '/kaggle/working/yolov5/runs/detect/exp'\n\n# Create the zip file\nshutil.make_archive('inference_on_imgs', 'zip', output_folder)\n\n# The zip file will be available in the '/kaggle/working/' directory for download\nprint(f\"Results zipped and saved as {folder_name} in the /kaggle/working/ directory.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Inference on one random test image:\n%cd /kaggle/working/yolov5/yolov5\nf_name = random.choice(os.listdir(test_path))\npath_2_image = os.path.join(test_path, f_name)\n!python detect.py --weights $weight_path --img 640 --conf 0.25 --source $path_2_image","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot the above image with it's predictions:\nimg = plt.imread(glob.glob(os.path.join('runs/detect/*', f_name))[0])\nplt.figure(figsize=(10,10));\nplt.imshow(img);","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python /kaggle/working/yolov5/detect.py --source /kaggle/input/temporary5 --weights /kaggle/input/temporary3/last.pt --conf 0.5 --imgsz 1300 --line-thickness 1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import zipfile\nimport requests\nimport cv2\nimport matplotlib.pyplot as plt\nimport glob \nimport random\nimport os","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to convert bounding boxes in YOLO format to xmin, ymin, xmax, ymax.\ndef yolo2bbox(bboxes):\n    xmin, ymin = bboxes[0]-bboxes[2]/2, bboxes[1]-bboxes[3]/2\n    xmax, ymax = bboxes[0]+bboxes[2]/2, bboxes[1]+bboxes[3]/2\n    return xmin, ymin, xmax, ymax","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Path to your dataset directory containing images\ndataset_dir = \"C:\\\\Users\\\\thatw\\\\\\\\akash\\\\Suhora Project\\\\HRSID_jpg\\\\HRSID_JPG\\\\JPEGImages\"\n\n# Path to your annotation file\nannotation_file = \"C:\\\\Users\\\\thatw\\\\akash\\\\Suhora Project\\\\HRSID_jpg\\\\HRSID_JPG\\\\annotations\\\\train2017.json\"  # Assuming annotations folder is located inside the dataset directory\nannotation_path = os.path.join(dataset_dir, \"..\", annotation_file)\n\n# Load annotation data\nwith open(annotation_path, 'r') as f:\n    annotation_data = json.load(f)\n\n# Randomly select 5 images\nrandom_images = random.sample(annotation_data['images'], 5)\n\n# Create subplots\nfig, axes = plt.subplots(1, 5, figsize=(15, 3))\n\n# Loop through each randomly selected image\nfor ax, image_info in zip(axes, random_images):\n    img_file = image_info['file_name']\n    img_id = image_info['id']\n\n    img_path = os.path.join(dataset_dir, img_file)\n\n    # Load the image\n    image = cv2.imread(img_path)\n\n    # Find annotations for this image\n    annotations = [ann for ann in annotation_data['annotations'] if ann['image_id'] == img_id]\n\n    # Process annotations and draw bounding boxes on the image\n    for annotation in annotations:\n        bbox = annotation['bbox']\n        x, y, w, h = bbox\n        cv2.rectangle(image, (int(x), int(y)), (int(x + w), int(y + h)), (0, 255, 0), 2)\n\n    # Convert the image from BGR to RGB (matplotlib uses RGB)\n    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n    # Display the image with annotations\n    ax.imshow(image_rgb)\n    ax.axis('on')\n\nplt.subplots_adjust(wspace=0.05)\nplt.tight_layout()\nplt.show()\n\nprint(\"Mapping complete.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}